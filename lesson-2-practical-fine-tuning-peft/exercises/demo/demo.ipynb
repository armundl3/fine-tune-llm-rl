{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Fine-Tuning Demo\n",
    "\n",
    "This notebook demonstrates how to configure LoRA (Low-Rank Adaptation) parameters for sentiment analysis fine-tuning on movie reviews. It uses an NPC (Natural Processing Component) to recommend optimal hyperparameters based on the dataset characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from npcpy.npc_compiler import NPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Define a function to prepare movie review data using the 20newsgroups dataset as a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_movie_review_data():\n",
    "    # Using 20newsgroups as proxy for review data\n",
    "    categories = ['rec.arts.movies.current-films', 'rec.arts.movies.past-films']\n",
    "    newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "    \n",
    "    reviews = []\n",
    "    for text, label in zip(newsgroups.data[:100], newsgroups.target[:100]):\n",
    "        sentiment = 'positive' if len(text.split()) > 50 else 'negative'  # Simple heuristic\n",
    "        reviews.append({'text': text[:200], 'sentiment': sentiment})\n",
    "    \n",
    "    return pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Preparation\n",
    "\n",
    "Generate the dataset and examine the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_movie_review_data()\n",
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Configuration Demo\n",
    "\n",
    "Define a function that uses an NPC to recommend optimal LoRA hyperparameters based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_review_lora_demo():\n",
    "    df = prepare_movie_review_data()\n",
    "    \n",
    "    trainer_npc = NPC(\n",
    "        name='LoRA Trainer',\n",
    "        primary_directive='Configure LoRA parameters for sentiment analysis fine-tuning',\n",
    "        model='llama3.2',\n",
    "        provider='ollama'\n",
    "    )\n",
    "    \n",
    "    config_format = '''\n",
    "    {\"lora_config\": {\n",
    "        \"r\": 16,\n",
    "        \"lora_alpha\": 32, \n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "        \"lora_dropout\": 0.05,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"epochs\": 3\n",
    "    }}\n",
    "    '''\n",
    "    \n",
    "    prompt = f\"\"\"Configure LoRA parameters for sentiment analysis on movie reviews.\n",
    "Dataset size: {len(df)} samples\n",
    "Task: Binary sentiment classification\n",
    "\n",
    "Recommend optimal LoRA hyperparameters.\n",
    "Format as: {config_format}\"\"\"\n",
    "    \n",
    "    response = trainer_npc.get_llm_response(prompt, format='json')\n",
    "    config = response['response']['lora_config']\n",
    "    \n",
    "    # Save training data and config\n",
    "    df.to_csv('movie_reviews_training.csv', index=False)\n",
    "    config_df = pd.DataFrame([config])\n",
    "    config_df.to_csv('lora_config.csv', index=False)\n",
    "    \n",
    "    print(\"LoRA configuration and training data prepared\")\n",
    "    print(f\"Config: {config}\")\n",
    "    return df, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Demo\n",
    "\n",
    "Execute the full LoRA configuration demo and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data, lora_config = movie_review_lora_demo()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DEMO RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nGenerated {len(movie_data)} training samples\")\n",
    "print(f\"\\nRecommended LoRA Configuration:\")\n",
    "for key, value in lora_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Generated Files\n",
    "\n",
    "Examine the CSV files that were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the training data CSV\n",
    "training_data = pd.read_csv('movie_reviews_training.csv')\n",
    "print(\"Training Data CSV:\")\n",
    "display(training_data.head(10))\n",
    "\n",
    "# Load and display the config CSV\n",
    "config_data = pd.read_csv('lora_config.csv')\n",
    "print(\"\\nLoRA Config CSV:\")\n",
    "display(config_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
