# Exercise: DPO for Patient Safety

### Objective
Use DPO to align an agent's reasoning process toward a specific goal (safety).

### Task
Use a pre-made preference dataset where 'chosen' traces come from the cautious SafetyFirst agent and 'rejected' traces from the InclusionFocused agent. Use the DPOTrainer to fine-tune a model and observe that it has learned to prioritize checking for exclusion criteria.

### Project Mapping
This lab is a direct, guided implementation of Phase 3: Reinforcement Learning Fine-Tuning.
